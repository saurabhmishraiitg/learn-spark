{
  "paragraphs": [
    {
      "text": "val rdd = sc.parallelize(Seq((1, \"Spark\"), (2, \"Databricks\")))\nval integerDS = rdd.toDS()\nintegerDS.show()",
      "user": "anonymous",
      "dateUpdated": "2020-05-17T21:36:56+0530",
      "config": {
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "graph": {
          "mode": "table",
          "height": 300,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "fontSize": 9,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+---+----------+\n| _1|        _2|\n+---+----------+\n|  1|     Spark|\n|  2|Databricks|\n+---+----------+\n\n\u001b[1m\u001b[34mrdd\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.rdd.RDD[(Int, String)]\u001b[0m = ParallelCollectionRDD[178] at parallelize at <console>:33\n\u001b[1m\u001b[34mintegerDS\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.Dataset[(Int, String)]\u001b[0m = [_1: int, _2: string]\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1589731331407_1894434324",
      "id": "20170918-193927_1318836494",
      "dateCreated": "2020-05-17T21:32:11+0530",
      "dateStarted": "2020-05-17T21:36:56+0530",
      "dateFinished": "2020-05-17T21:36:57+0530",
      "status": "FINISHED",
      "focus": true,
      "$$hashKey": "object:43525"
    },
    {
      "text": "case class Employee(name: String, age:Int, departmentId: Int, salary: Double)\ncase class Department(id: Int, name: String)\n\ncase class Record(name: String, age: Int, salary: Double, departmentId: Int, departmentName: String)\ncase class ResultSet(departmentId: Int, departmentName: String, avgSalary: Double)\n\nval employeeDataSet1 = sc.parallelize(Seq(Employee(\"Max\", 22, 1, 100000.0), Employee(\"Adam\", 33, 2, 93000.0), Employee(\"Eve\", 35, 2, 89999.0), Employee(\"Muller\", 39, 3, 120000.0))).toDS()\nval employeeDataSet2 = sc.parallelize(Seq(Employee(\"John\", 26, 1, 990000.0), Employee(\"Joe\", 38, 3, 115000.0))).toDS()\n\nval departmentDataSet = sc.parallelize(Seq(Department(1, \"Engineering\"), Department(2, \"Marketing\"), Department(3, \"Sales\"))).toDS()\nval employeeDataset = employeeDataSet1.union(employeeDataSet2)\n\nemployeeDataset.show()\nval averageSalaryDataset = employeeDataset.joinWith(departmentDataSet, $\"departmentId\" === $\"id\", \"inner\")\n                           \naverageSalaryDataset.show()",
      "user": "anonymous",
      "dateUpdated": "2020-05-17T21:52:38+0530",
      "config": {
        "colWidth": 12,
        "fontSize": 9,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+------+---+------------+--------+\n|  name|age|departmentId|  salary|\n+------+---+------------+--------+\n|   Max| 22|           1|100000.0|\n|  Adam| 33|           2| 93000.0|\n|   Eve| 35|           2| 89999.0|\n|Muller| 39|           3|120000.0|\n|  John| 26|           1|990000.0|\n|   Joe| 38|           3|115000.0|\n+------+---+------------+--------+\n\n+--------------------+----------------+\n|                  _1|              _2|\n+--------------------+----------------+\n|[Max, 22, 1, 1000...|[1, Engineering]|\n|[John, 26, 1, 990...|[1, Engineering]|\n|[Muller, 39, 3, 1...|      [3, Sales]|\n|[Joe, 38, 3, 1150...|      [3, Sales]|\n|[Adam, 33, 2, 930...|  [2, Marketing]|\n|[Eve, 35, 2, 8999...|  [2, Marketing]|\n+--------------------+----------------+\n\nimport sqlContext.implicits._\ndefined class Employee\ndefined class Department\ndefined class Record\ndefined class ResultSet\n\u001b[1m\u001b[34memployeeDataSet1\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.Dataset[Employee]\u001b[0m = [name: string, age: int ... 2 more fields]\n\u001b[1m\u001b[34memployeeDataSet2\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.Dataset[Employee]\u001b[0m = [name: string, age: int ... 2 more fields]\n\u001b[1m\u001b[34mdepartmentDataSet\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.Dataset[Department]\u001b[0m = [id: int, name: string]\n\u001b[1m\u001b[34memployeeDataset\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.Dataset[Employee]\u001b[0m = [name: string, age: int ... 2 more fields]\n\u001b[1m\u001b[34maverageSalaryDataset\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.Dataset[(Employee, Department)]\u001b[0m = [_1: struct<name: string, age: int ... 2 more fields>, _2: struct<id: int, n..."
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1589732113259_1468405343",
      "id": "paragraph_1589732113259_1468405343",
      "dateCreated": "2020-05-17T21:45:13+0530",
      "dateStarted": "2020-05-17T21:52:38+0530",
      "dateFinished": "2020-05-17T21:52:41+0530",
      "status": "FINISHED",
      "$$hashKey": "object:43526"
    },
    {
      "text": "\ncase class Company(name: String, foundingYear: Int, numEmployees: Int)\nval inputSeq = Seq(Company(\"ABC\", 1998, 310), Company(\"XYZ\", 1983, 904), Company(\"NOP\", 2005, 83))\nval df = sc.parallelize(inputSeq).toDF()\n\nval companyDS = df.as[Company]\ncompanyDS.show()",
      "user": "anonymous",
      "dateUpdated": "2020-05-17T21:37:25+0530",
      "config": {
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "graph": {
          "mode": "table",
          "height": 300,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "fontSize": 9,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+----+------------+------------+\n|name|foundingYear|numEmployees|\n+----+------------+------------+\n| ABC|        1998|         310|\n| XYZ|        1983|         904|\n| NOP|        2005|          83|\n+----+------------+------------+\n\nimport sqlContext.implicits._\ndefined class Company\n\u001b[1m\u001b[34minputSeq\u001b[0m: \u001b[1m\u001b[32mSeq[Company]\u001b[0m = List(Company(ABC,1998,310), Company(XYZ,1983,904), Company(NOP,2005,83))\n\u001b[1m\u001b[34mdf\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [name: string, foundingYear: int ... 1 more field]\n\u001b[1m\u001b[34mcompanyDS\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.Dataset[Company]\u001b[0m = [name: string, foundingYear: int ... 1 more field]\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1589731331412_2052918751",
      "id": "20170918-193352_946504264",
      "dateCreated": "2020-05-17T21:32:11+0530",
      "dateStarted": "2020-05-17T21:37:25+0530",
      "dateFinished": "2020-05-17T21:37:28+0530",
      "status": "FINISHED",
      "$$hashKey": "object:43527"
    },
    {
      "text": "",
      "user": "anonymous",
      "dateUpdated": "2020-05-17T21:32:11+0530",
      "config": {
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "graph": {
          "mode": "table",
          "height": 300,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "fontSize": 9,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1589731331413_-1508712578",
      "id": "20170918-193844_1208851102",
      "dateCreated": "2020-05-17T21:32:11+0530",
      "status": "READY",
      "$$hashKey": "object:43528"
    }
  ],
  "name": "DataSet Example",
  "id": "2FAMGFAPX",
  "defaultInterpreterGroup": "spark",
  "version": "0.9.0-preview1",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false,
    "looknfeel": "default",
    "personalizedMode": "false"
  },
  "info": {},
  "path": "/DataSet Example"
}